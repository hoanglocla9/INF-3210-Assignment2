This repository is based on SparseGPT paper [1] and its original repository [2]
[1] Frantar, Elias, and Dan Alistarh. "Sparsegpt: Massive language models can be accurately pruned in one-shot." International conference on machine learning. PMLR, 2023.
[2] https://github.com/IST-DASLab/sparsegpt
